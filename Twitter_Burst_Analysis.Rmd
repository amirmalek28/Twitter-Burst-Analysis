---
title: "Twitter Burst Analysis"
author: "Amir Malek"
date: "4/30/2021"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=TRUE}

rm(list = ls())
setwd("/Users/amirmalek/Desktop/NYU/Spring 2021/DSGA 1015/Project")

```

```{r echo=TRUE}


```


```{r echo=TRUE}

# install.packages("flextable")
library(flextable)
library(gt)
library(kableExtra)
library(bursts)
library(readtext)
library(tm)
library(reactable)
library(rtweet)
library(ggplot2)
library(tidyverse)
library(quanteda)
library(data.table)
library(stringr)
library(ngram)
library(lemon)
```


```{r echo=TRUE}




```


```{r echo=TRUE}

tweets_mixed <- search_tweets(
  "filter:verified OR -filter:verified", n = 1000, geocode = lookup_coords("usa"), since = "2021-04-29", include_rts = FALSE, until = "2021-05-01", retryonratelimit = TRUE)

```
```{r echo=TRUE}

tweets_popular <- search_tweets(
  "filter:verified OR -filter:verified", n = 100, type = "popular")

```


```{r echo=TRUE}

stream_df <- stream_tweets(q = lookup_coords("USA"), n = 5000, timeout = 120)
stream_df <- as.data.frame(stream_df)

#number of hours to run
hours <- 12
#stream every x minutes
minutes <- 15
#stream for y seconds
seconds <- 120
seq_loop <- (60/minutes)*hours

trending <- vector(mode = "list", length = seq_loop)

for (i in seq_len(seq_loop)) {
    message("Starting stream ", i)
    streamer  <- stream_tweets(q = lookup_coords("USA"), n = 5000, timeout = seconds)
    message("Collected ", nrow(streamer), " tweets")
    streamer <- as.data.frame(streamer)
    stream_df <- rbind(stream_df, streamer)
    message("Appended stream_df and streamer")
    trending[[i]] <- get_trends("united states")
    message("Updated current US trends")

    Sys.sleep(minutes*60)
}


#stream_function(1)
```


```{r echo=TRUE}




```

```{r echo=TRUE}

ts_plot(twitter_data[1:50683,], "minutes") +
  labs(x = NULL, y = NULL,
       title = "Frequency of tweets",
       subtitle = paste0(format(min(twitter_data$created_at), "%d %B %Y"), " to ", format(max(twitter_data$created_at),"%d %B %Y")),
       caption = "Data collected from Twitter's REST API via rtweet") + labs(x= "time", y="number of tweets")
  theme_minimal()


```


```{r echo=TRUE}

twitter_data_small <- readRDS("twitter_data_small.rds")
trending_small <- readRDS("trending_small.rds")


trending <- readRDS("trending_large.rds")
twitter_data <- readRDS("twitter_data_large.rds")

```



```{r echo=TRUE}

bursty <- function(word, DTM, date) {
  word.vec <- DTM[, which(colnames(DTM) == word)]
  if(length(word.vec) == 0) {
    print(paste(word, " does not exist in this corpus."))
    return()
  } 
  else {
    word.times <- c(0,which(as.vector(word.vec)>0))
    
    kl <- kleinberg(word.times, gamma = 0.5)
    kl$start <- date[kl$start+1]
    kl$end <- date[kl$end]
    max_level <- max(kl$level)
    
    plot(c(kl$start[1], kl$end[1]), c(1,max_level),
         type = "n", xlab = "Time", ylab = "Level", bty = "n",
         xlim = c(0,2400), ylim = c(1, max_level),
         yaxt = "n", main = paste("Burstiness of ", word, "over time") )
    axis(2, at = 1:max_level)
    
    for (i in 1:nrow(kl)) {
      if (kl$start[i] != kl$end[i]) {
        arrows(kl$start[i], kl$level[i], kl$end[i], kl$level[i], code = 3, angle = 90,
               length = 0.05)
      } 
      else {
        points(kl$start[i], kl$level[i])
      }
    }
    #xlim = c(min(date), max(date))
    print(kl)
  }
}

#select relevant columns
twitter_data_comp <-twitter_data[1:50683,]%>% select(3,5,17)

#create corpus
twitter_corpus <- corpus(twitter_data_comp, text_field = "text")

#remove punctuation from created at date
docvars(twitter_corpus)$created_at <- (gsub("[[:punct:]]","",docvars(twitter_corpus)$created_at))

#remove whitespace
docvars(twitter_corpus)$created_at <- (gsub(" ","",docvars(twitter_corpus)$created_at))

#remove alphanumeric characters from date
docvars(twitter_corpus)$created_at <- (gsub("[[:alpha:]]","",docvars(twitter_corpus)$created_at))

#remove date
docvars(twitter_corpus)$created_at <- (gsub("20210502","",docvars(twitter_corpus)$created_at))
docvars(twitter_corpus)$created_at <- (gsub("20210503","",docvars(twitter_corpus)$created_at))

docvars(twitter_corpus)$created_at <- as.numeric(substr(docvars(twitter_corpus)$created_at,1,
                                                        nchar(docvars(twitter_corpus)$created_at)-2))

twitter_data_ngrams <- tokens(twitter_data_comp$text)
twitter_data_ngrams <- tokens_ngrams(twitter_data_ngrams, n = c(1L, 2L, 3L))

#create dfm with filters
twitter_dfm <- dfm(twitter_data_ngrams, stem = F, remove_punct = F,
        tolower = T, remove_numbers = F,   remove = c(stopwords("english"),
            "http","https","rt", "t.co", ".", ",","!","?",":",";","&","-",")","/","\U0001f602","\U0001f923","(","@",'"'))


# twitter_dfm <- dfm(twitter_corpus, stem = F, remove_punct = F, tolower = T, remove_numbers = F,   remove = c(stopwords("english"), "http","https","rt", "t.co", ".", ",","!","?",":",";","&","-",")","/","\U0001f602","\U0001f923","(","@",'"'))

topfeatures <- topfeatures(twitter_dfm, 100000)
topfeatures <- as.data.frame(topfeatures)
#topfeatures <- data.frame(matrix(unlist(topfeatures), ncol = max(lengths(topfeatures)), byrow = TRUE))

#docvars(twitter_corpus)
```

```{r echo=TRUE}
#visualize burstiness

bursty("billie", twitter_dfm, docvars(twitter_corpus)$created_at)
trafford_burst$duration <- trafford_burst$end - trafford_burst$start
max(trafford_burst$level)
```

```{r echo=TRUE}

iter <- 70

words_to_search <- "billie"

twitter_data_filter<- twitter_data[1:50683,]

#twitter_data_filter<-twitter_data_ngrams

twitter_data_filter$text <- tolower(twitter_data_filter$text)

twitter_data_filter<- twitter_data_filter %>% filter(grepl(words_to_search, text))  %>% select(3,5,17)

#remove punct from created_at time
twitter_data_filter$created_at <- (gsub("[[:punct:]]","",twitter_data_filter$created_at))

#remove whitespace
twitter_data_filter$created_at <- (gsub(" ","",twitter_data_filter$created_at))

#remove date from created_date
twitter_data_filter$created_at <- (gsub("20210502","",twitter_data_filter$created_at))
twitter_data_filter$created_at <- (gsub("20210503","",twitter_data_filter$created_at))

#remove seconds from time, only hours and minutes
twitter_data_filter$created_at <- substr(twitter_data_filter$created_at,1,nchar(twitter_data_filter$created_at)-2)

#group by minute
twitter_data_filter <- twitter_data_filter %>% group_by(created_at) %>% summarise(n=n())

twitter_data_filter[,1] <- sapply(twitter_data_filter[,1], as.numeric)

created_at <- seq(0,2300, by = 1)
n <- rep(0,2301)
temp_df <- data.frame(created_at, n)

#twitter_data_filter <- merge(temp_df, twitter_data_filter, by.x = "created_at", by.y = "created_at")
twitter_data_filter$created_at <- floor(twitter_data_filter$created_at)

twitter_data_filter <- left_join(temp_df,twitter_data_filter, by = "created_at")

twitter_data_filter$n <-twitter_data_filter$n.x + twitter_data_filter$n.y

twitter_data_filter <- twitter_data_filter %>% select(1,4)

twitter_data_filter$n[is.na(twitter_data_filter$n)] <- 0

#twitter_data_filter <- sapply(twitter_data_filter, as.numeric)

#unlist
#twitter_data_filter <- as.numeric(unlist(twitter_data_filter))

ggplot(twitter_data_filter, aes(created_at, n)) + geom_bar(stat = "identity", width = 10)  + labs(title= paste("Number of ", words_to_search, "tweets")  ,x="Time", y = "Number of tweets")
```


```{r echo=TRUE}

# getting trends ranking as set of columns
trends_df <- as.data.frame(trending[1])
trends_df <- trends_df %>% select(1)
names(trends_df)[1] <- 1

trend_seq <- c(2:iter)

for (i in trend_seq) {
trends_df_temp <- as.data.frame(trending[i])
trends_df_temp <- trends_df_temp %>% select(1)
trends_df <- cbind(trends_df, new_col = trends_df_temp$trend)

}

```

```{r echo=TRUE}

trend_to_rank <- "billie"

trend_ranking <- vector()
ranking_seq <- c(1:iter)
for (i in ranking_seq) {
rank <- which(grepl(trend_to_rank, trends_df[,i]))

if (length(rank) > 0) {
trend_ranking <- append (trend_ranking, 51 - rank)
}
else {
trend_ranking <- append (trend_ranking, 0)

}
}

```

```{r echo=TRUE}


rank_date_df <- as.data.frame(trending[1])
rank_date_df <- rank_date_df %>% select(8)
names(trends_df)[1] <- 1

trend_seq <- c(2:iter)

for (i in trend_seq) {
rank_date_df_temp <- as.data.frame(trending[i])
rank_date_df_temp <- rank_date_df_temp %>% select(8)
rank_date_df <- cbind(rank_date_df, new_col = rank_date_df_temp$as_of)

}

rank_date_df <- head(rank_date_df,1)

ranking_seq <- c(1:iter)

for (i in ranking_seq) {
  
#remove punct from created_at time
rank_date_df[,i] <- (gsub("[[:punct:]]","",rank_date_df[,i]))

#remove whitespace
rank_date_df[,i] <- (gsub(" ","",rank_date_df[,i]))

#remove date
rank_date_df[,i] <- (gsub("20210502","",rank_date_df[,i]))
rank_date_df[,i] <- (gsub("20210503","",rank_date_df[,i]))

#remove seconds from time
rank_date_df[,i] <- substr(rank_date_df[,i],1,nchar(rank_date_df[,i])-2)

#add : tp time for readability
rank_date_df[,i] <- sub("([[:digit:]]{2,2})$", ":\\1", rank_date_df[,i])

}

rank_date_df <- t(rank_date_df)
```

```{r echo=TRUE}

#combining date/time and ranking data
trend_rank_df <- data.frame(rank_date_df, trend_ranking)
names(trend_rank_df)[1] <- "time"
names(trend_rank_df)[2] <- "rank"

#ggplot(trend_rank_df, aes(time, rank)) + geom_point() 

#ranking plot

ggplot(trend_rank_df, aes(time, rank, group = 1)) + 
  geom_line() + labs(title= paste("Trend ranking of ", trend_to_rank)  ,x="Time", y = "Rank") +
    theme(axis.text.x = element_text(angle = 60)) +theme(axis.text=element_text(hjust = 1, size=8), axis.title=element_text(size=14)) +
      scale_y_continuous(labels=c(50, 40, 30, 20, 10, 1), breaks=seq(0,50,10), limits=c(0,50))
```

```{r echo=TRUE}

#average ranking- not including unranked 0s
#max burst level

ranking_seq <- c(1:iter)
all_trends_ranked <- data.frame(trend = character(), mean_ranking = numeric(), best_ranking = numeric() )
for (i in seq_len(50)) {
  for (j in seq_len(80)){
    trend_to_rank <- trends_df[j,i]
    trend_ranking <- vector()
    for (i in ranking_seq) {
      rank <- which(grepl(trend_to_rank, trends_df[,i]))
      if (length(rank) > 0) {
        trend_ranking <- append (trend_ranking, rank)}
      else {
        trend_ranking <- append (trend_ranking, 0)
  }
}

mean_ranking <- mean(trend_ranking[trend_ranking>0])
best_ranking <- min(trend_ranking[trend_ranking>0])
row_temp <- c(trend_to_rank, mean_ranking, best_ranking)
all_trends_ranked <- rbind(all_trends_ranked, row_temp)

  }
}

names(all_trends_ranked)[1] <- "trend"
names(all_trends_ranked)[2] <- "mean_ranking"
names(all_trends_ranked)[3] <- "best_ranking"

all_trends_ranked <- all_trends_ranked [complete.cases(all_trends_ranked), ]
all_trends_ranked <- distinct(all_trends_ranked)
all_trends_ranked$best_ranking <- as.numeric (all_trends_ranked$best_ranking)



# ggplot(trend_rank_df, aes(time, rank, group = 1)) + 
#   geom_line() + labs(title= paste("Trend ranking of ", trend_to_rank)  ,x="Time", y = "Rank") +
#     theme(axis.text.x = element_text(angle = 60)) +theme(axis.text=element_text(hjust = 1, size=5), axis.title=element_text(size=14)) 
#       

```

```{r echo=TRUE}

all_trends_ranked <- all_trends_ranked_save

bursty_values <- function(word, DTM, date) {
  word.vec <- DTM[, which(colnames(DTM) == word)]
  if(length(word.vec) == 0) {
    print(paste(word, " does not exist in this corpus."))
    return()
  } 
  else {
    word.times <- c(0,which(as.vector(word.vec)>0))
    kl <- kleinberg(word.times, gamma = 0.5)
    kl$start <- date[kl$start+1]
    kl$end <- date[kl$end]
    max_level <- max(kl$level)
    invisible(kl)
  }
}
    

all_trends_ranked$trend <- tolower(all_trends_ranked$trend)
all_trends_ranked$trend <- (gsub(" ","_",all_trends_ranked$trend))

for (i in seq_len(nrow(all_trends_ranked))){
burst <- bursty_values(all_trends_ranked$trend[i], twitter_dfm, docvars(twitter_corpus)$created_at)
if (is.null(burst) == T) {
  all_trends_ranked$max_burst_level[i] <- 0
  all_trends_ranked$max_burst_duration[i] <-  0
  all_trends_ranked$min_burst_duration[i] <-  0

  next
}
burst$duration <- burst$end - burst$start
all_trends_ranked$max_burst_level[i] <- max(burst$level)
all_trends_ranked$max_burst_duration[i] <-  max(burst$duration)
all_trends_ranked$min_burst_duration[i] <-  min(burst$duration)
all_trends_ranked$avg_burst_duration[i] <- mean(burst$duration)

}

for (i in seq_len(nrow(all_trends_ranked))){
  words_to_search <- all_trends_ranked$trend[i]
  all_trends_ranked$number_of_mentions[i] <-  topfeatures[words_to_search,]
}

all_trends_ranked <- all_trends_ranked[order(all_trends_ranked[,3], -all_trends_ranked[,4]),]

flextable(all_trends_ranked)
```

```{r echo=TRUE}

rank_vs_burst <- aggregate(all_trends_ranked[, 4], list(all_trends_ranked$best_ranking), mean)
names(rank_vs_burst)[1] <- "ranking"
names(rank_vs_burst)[2] <- "burst_level"
ggplot(rank_vs_burst, aes(ranking, burst_level)) + geom_point() + geom_smooth(method='lm', formula= y~x)+ labs(title= "Mean Burst Level over Increasing Rankings"  ,x="Ranking", y = "Mean Burst Level")


rank_vs_burst_dur <- aggregate(all_trends_ranked[, 5], list(all_trends_ranked$best_ranking), mean)
names(rank_vs_burst_dur)[1] <- "ranking"
names(rank_vs_burst_dur)[2] <- "max_duration"
ggplot(rank_vs_burst_dur, aes(ranking, max_duration)) + geom_point() + geom_smooth(method='lm', formula= y~x)+ labs(title= "Mean Max Duration over Increasing Rankings"  ,x="Ranking", y = "Mean Max Duration")


rank_vs_burst_mindur <- aggregate(all_trends_ranked[, 6], list(all_trends_ranked$best_ranking), mean)
names(rank_vs_burst_mindur)[1] <- "ranking"
names(rank_vs_burst_mindur)[2] <- "min_duration"
ggplot(rank_vs_burst_mindur, aes(ranking, min_duration)) + geom_point() + geom_smooth(method='lm', formula= y~x) + labs(title= "Mean Minimum Duration over Increasing Rankings"  ,x="Ranking", y = "Mean Min Duration")

rank_vs_burst_avgdur <- aggregate(all_trends_ranked[, 7], list(all_trends_ranked$best_ranking), mean)
names(rank_vs_burst_avgdur)[1] <- "ranking"
names(rank_vs_burst_avgdur)[2] <- "avg_duration"
ggplot(rank_vs_burst_avgdur, aes(ranking, avg_duration)) + geom_point() + geom_smooth(method='lm', formula= y~x) + labs(title= "Mean Burst Duration over Increasing Rankings"  ,x="Ranking", y = "Mean Burst Duration")


rank_vs_mentions <- all_trends_ranked %>% select(3,8) 
rank_vs_mentions <- rank_vs_mentions [complete.cases(rank_vs_mentions), ]
rank_vs_mentions <- aggregate(rank_vs_mentions[, 2], list(rank_vs_mentions$best_ranking), mean)
names(rank_vs_mentions)[1] <- "ranking"
names(rank_vs_mentions)[2] <- "number_of_mentions"
ggplot(rank_vs_mentions, aes(ranking, number_of_mentions)) + geom_point() + geom_smooth(method='lm', formula= y~x) + labs(title= "Mean Number of Mentions over Increasing Rankings"  ,x="Ranking", y = "Mean Number of Mentions")

mindur_vs_burst <- aggregate(all_trends_ranked[, 4], list(all_trends_ranked$min_burst_duration), mean)
names(mindur_vs_burst)[1] <- "min_burst_duration"
names(mindur_vs_burst)[2] <- "burst_level"
ggplot(mindur_vs_burst, aes(min_burst_duration, burst_level)) + geom_point() + geom_smooth(method='lm', formula= y~x) + labs(title= "Max Burst Level over Mean Min Burst Duration"  ,x="min_burst_duration", y = "Max Burst level")
```
